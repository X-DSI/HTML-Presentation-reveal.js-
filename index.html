<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>My Experience</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides" >
				<!--Slide 1-->
				<section data-transition="zoom"> <h1>Hi There!</h1></section>
				<!--Slide 2-->
				<section data-transition="zoom"><h3>My Experience at Bennett University</h3></section>
				<!--Slide 3-->
				<section id="fragments">
					<h4>I Learned</h4>
					<br>
					<p class="fragment">To be <span class="fragment">HUMBLE!</span></p>
					<blockquote class="fragment">
						&ldquo;There are always people who fight a greater fight than yours'!&rdquo;
					</blockquote>
				</section>
				<!--Slide 4-->
				<section data-transition="zoom">
					<section>
						<h4>My Project</h4>
						<p class="fragment">Semi-Supervised Video Object Segmentation</p>
					</section>
					<section>
						<h5>The Problem</h5>
						<h7>Bounding Boxes</h7>
						<img src="/home/xdsi/Documents/HTML Presentation (Reveal.js)/src/boundingbox.jpg" height="480" width="980">
					</section>
					<section>
						<p>Imagine</p>
					</section>
					<section>
						<h4>Driverless cars <span>AKA</span> Autonomous Vehicles</h4>
						<video autoplay loop src="/home/xdsi/Documents/HTML Presentation (Reveal.js)/src/Full Self-Driving.mp4" height="480" width="960">Play</video>
					</section>
					<section>
						<h4>How does the car see??</h4>
						<video autoplay loop src="/home/xdsi/Documents/HTML Presentation (Reveal.js)/src/4K Mask RCNN COCO Object detection and segmentation _2 0s - 2m60s (OOT3UIXZztE).mp4" height="480" width="960"></video>
					</section>
				</section>
				<!--Slide 5-->
				<section data-transition="zoom">
					<section>
						<h4>Our Approach</h4>
					</section>
					<section>
						<h5>Project Details</h5>
						<p class="fragment">One Shot Video Object Segmentation (OSVOS)</p>
						<p class="fragment">First Frame of the Video is anotated</p>
						<p class="fragment">CNN</p>
					</section>
					<section>
						<h5>Datasets</h5>
						<p class="fragment">Densly Anotated Video Object Segmentation (DAVIS)</p>
						<p class="fragment"> 480p & 1080p Footages</p>
					</section>
					<section>
							<h2>Let's see some Code!</h2>
							<pre><code class="hljs" data-trim data-line-numbers="2,10-14">
									import numpy as np
									import tensorflow as tf
									slim = tf.contrib.slim
									import matplotlib.pyplot as plt
									root_folder = os.path.dirname(os.path.realpath(__file__))
									sys.path.append(os.path.abspath(root_folder))
									import osvos
									from dataset import Dataset
									os.chdir(root_folder)
									seq_name = "camel"
									gpu_id = 0
									train_model = True
									result_path = os.path.join('DAVIS', 'Results', 
											'Segmentations', '1080p', 'OSVOS', seq_name)
							</code></pre>
						</section>
						<section>
								<pre><code class="hljs" data-trim data-line-numbers="2-5">
										# Train parameters
										parent_path = os.path.join('models', 'OSVOS_parent',
											 'OSVOS_parent.ckpt-50000')
										logs_path = os.path.join('models', seq_name)
										max_training_iters = 5000
								</code></pre>
						</section>
						<section>
							<pre><code class="hljs" data-trim data-line-numbers="2-6">
								# Test the network
								with tf.Graph().as_default():
									with tf.device('/gpu:' + str(gpu_id)):
										checkpoint_path = os.path.join('models', seq_name, 
											seq_name+'.ckpt-'+str(max_training_iters))
										osvos.test(dataset, checkpoint_path, result_path)
							</code></pre>
					</section>
					<section data-transition="zoom">
						<h3>Supercomputer</h3>
						<p class="fragment">Nvidia DGX Tesla V100</p>
						<img class="fragment" src="/home/xdsi/Documents/HTML Presentation (Reveal.js)/src/dgx tesla v100.png" height="480" width="1080">
					</section>
					<section data-background-video="/home/xdsi/Documents/HTML Presentation (Reveal.js)/src/A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation.mp4" data-background-color="#000000">
						<div style="background-color: rgba(255, 255, 255, 0.26); color: #000; padding: 20px;">
							<h2>Our Output</h2>
						</div>
					</section>
				</section>
				<!--Slide 6-->
				<section data-transition="zoom">
					<section>
						Future Plans...
					</section>
					<section>

					</section>
				</section>
			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
